\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsfonts, amsthm, graphicx, mathrsfs, relsize, euscript, stmaryrd, float}
\usepackage[labelsep=period, font=footnotesize, labelfont=bf]{caption}
\oddsidemargin = 1 cm
\textwidth = 15 cm


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{thm}[theorem]{Theorem}
\newtheorem{predefinition}[theorem]{{\bf Definition}}
\newenvironment{definition}{\begin{predefinition}\rm{\hspace{-0.5 em}{\bf}}}{\end{predefinition}}
\newtheorem{prequestion}[theorem]{{\bf Question}}
\newenvironment{question}{\begin{prequestion}\rm{\hspace{-0.5 em}{\bf}}}{\end{prequestion}}
\newtheorem{preremark}[theorem]{{\bf Remark}}
\newenvironment{remark}{\begin{preremark}\rm{\hspace{-0.5 em}{\bf}}}{\end{preremark}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\DeclareMathAlphabet{\mathbbmsl}{U}{bbm}{m}{sl}
\newcommand{\bmi}[1]{\mbox{\boldmath $ #1$}}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeatletter
\DeclareRobustCommand\widecheck[1]{{\mathpalette\@widecheck{#1}}}
\def\@widecheck#1#2{%
    \setbox\z@\hbox{\m@th$#1#2$}%
    \setbox\tw@\hbox{\m@th$#1%
       \widehat{%
          \vrule\@width\z@\@height\ht\z@
          \vrule\@height\z@\@width\wd\z@}$}%
    \dp\tw@-\ht\z@
    \@tempdima\ht\z@ \advance\@tempdima2\ht\tw@ \divide\@tempdima\thr@@
    \setbox\tw@\hbox{%
       \raise\@tempdima\hbox{\scalebox{1}[-1]{\lower\@tempdima\box
\tw@}}}%
    {\ooalign{\box\tw@ \cr \box\z@}}}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\title{Threshold for weak saturation stability\\[4mm]}

\author{
	M.R.  Bidgoli$^{^1}$  \quad  A. Mohammadian$^{^2}$  \quad   B. Tayfeh-Rezaie$^{^1}$ \quad   M. Zhukovskii$^{^{3,4,5}}$ \\[6mm]
	$^{^1}$School of Mathematics,\\
	Institute for Research in Fundamental Sciences\,(IPM),\\
	P.O. Box 19395-5746, Tehran, Iran\\[3mm]
	$^{^2}$School of Mathematical Sciences, Anhui University,\\
	Hefei 230601, Anhui,  China\\[3mm]
	$^{^3}$Laboratory of combinatorial and geometric structures, MIPT \\ Moscow Region 141701, Russian Federation\\[3mm]
	$^{^4}$Adyghe State University, Caucasus mathematical center\\ Republic of Adygea, 385000, Russian Federation\\[3mm]
    $^{^5}$RANEPA, Moscow, 119571, Russian Federation\\[8mm]
	\textsf{bd}@\textsf{ipm.ir}  \qquad  \textsf{ali{\_}m}@\textsf{ahu.edu.cn} \qquad  \textsf{tayfeh-r}@\textsf{ipm.ir} \qquad  \textsf{zhukmax}@\textsf{gmail.com}\\[8mm]
}




\date{}


\begin{document}


\maketitle


\begin{abstract}
We study $\mathrm{wsat}\big({G}(n, p), K_s\big)$, the weak $K_s$-saturation number of the Erd\H{o}s--R\'enyi random graph $G(n, p)$, where $K_s$ is the complete graph on $s$ vertices. Kor\'{a}ndi and Sudakov proved that the weak $K_s$-saturation number of $K_n$ is stable, i.e. it remains the same after removing edges with constant probability. We prove that there exists a threshold function for this stability property and give upper and lower bounds on the threshold. Having this, we simplify the proof of Kor\'andi and Sudakov and make their result more general. A general upper bound for  $\mathrm{wsat}\big({G}(n, p), K_s\big)$ is also provided.
\\[.3cm]
\noindent {\bf Keywords:}    Weak saturation,  Random graph, Stability. \\[1mm]
\noindent {\bf AMS Mathematics Subject Classification\,(2020):}    05C80, 05C35, 60K35. \\[6mm]
\end{abstract}



\section{Introduction}


Given a graph $F$, an {\it $F$-bootstrap percolation process} is a sequence of graphs $H_0\subset H_1\subset\cdots\subset H_m$ such that, for every $i\in\{1,\ldots,m\}$, $H_{i}$ is obtained from $H_{i-1}$ by adding an edge that belongs to a copy of $F$ in $H_i$. $F$-bootstrap process was introduced by Bollobas 50 years ago~\cite{bol} and can be seen as a special case of the `cellular automata' introduced by von Neumann~\cite{Neumann} after a suggestion of Ulam~\cite{Ulam}. $F$-bootstrap percolation is also similar to $r$-neighborhood bootstrap percolation model having applications in physics (see, e.g.,~\cite{Adler,Fontes,Morris}).

A fundamental question about bootstrap percolation is, how large is the smallest possible percolating set in $F$-bootstrap process? Formally, given two graphs $G$ and $F$,  a spanning subgraph  $H$  of $G$  is  said to be a  {\it weakly $F$-saturated subgraph of $G$} if $H$ contains no subgraph  isomorphic to $F$ and there exists an $F$-bootstrap percolation process $H=H_0\subset H_1\subset\cdots\subset H_m=G$. The  minimum number of edges  in  a weakly $F$-saturated  subgraph of $G$ is called the {\it weak $F$-saturation number} of $G$, denoted by $\mathrm{wsat}(G, F)$.

As usual, we denote by $G(n,p)$, the binomial random graph on vertex set $[n]:=\{1,\ldots,n\}$ with the edge probability $p$ (recall that this graph contains every edge with probability $p$ independently of all the others).
Kor\'andi and   Sudakov   initiated  the study of  weak saturation numbers of random graphs in \cite{kor}. They   proved that, for every fixed $p\in(0, 1)$ and integer  $s\geqslant 3$, $\mathrm{wsat}\big({G}(n, p), K_s\big)=\mathrm{wsat}\big(K_n, K_s\big)$ whp (this is the abbreviation for the common notion `with high probability' meaning with a probability approaching 1 as $n\to\infty$), which is in turn ${s-2 \choose 2}+(n-s+2)(s-2)$ by a classic result proved by Lov\'{a}sz \cite{L77}. 
Other proofs of this result have been obtained by Frankl \cite{Frankl82}, Kalai \cite{Kalai84,Kalai85}, Alon \cite{Alon85} and Yu \cite{Yu93}.
For  a  description of Kalai's proof, see \cite{Faudree11}.
%, Frankl \cite{Frankl}, and Kalai \cite{Kalai}.
Kor\'andi and Sudakov also noticed that the same is true for $p\geqslant n^{-\varepsilon}$ for small
enough $\varepsilon> 0$ and asked about smaller $p$ and about possible {\it threshold probability}~\cite[Chapter 1.5]{RG} for the
property of having the weak $K_s$-saturation number exactly ${s-2 \choose 2}+(n-s+2)(s-2)$. Let us denote this property by $\mathcal{A}_s$. 
In this paper, we prove that this threshold exists and present lower and upper bounds on that.

%To have a better insight on the problem, notice that the special case $s=3$ is equivalent to following question. Is there whp a weakly $K_3$-saturated spanning tree in $G(n,p)$? Notice that a spanning substar (which is a tree with depth 1) is weakly $K_3$-saturated in $K_n$ (but it is not embedded in $G(n,p)$). In the paper, we prove that, for $p\gg\sqrt[3]{\ln n / n}$ (here and further in the paper, we write $f\ll g$   ($g\gg f$) if $\lim_{n\rightarrow\infty}\tfrac{f(n)}{g(n)}=0$), there are weakly $K_3$-saturated trees of depth $2$ in $G(n,p)$ whp. However, for small $p$, `deep' trees may work better since, by counting degrees of vertices and edges that appear in the bootstrap percolation process, one can show (we do not do it in this paper) that there is no weakly $K_3$-saturated tree of depth two in $G(n,p)$ for $p<n^{-\frac 25+o(1)}$ whp. However, the question about existence of a deeper  $K_3$-saturated tree for such $p$ remains open. Notice that, in the same manner (we skip the details in this paper), one can show, that, for $p\gg\sqrt[3]{\ln n / n}$, there exists a weakly $K_3$-saturated Hamiltonian path in $G(n,p)$ whp.\\

The rest of the paper is organized as follows. In the next section, we fix the notation used in the paper and recall the theorems that we have referred to. In Section \ref{secLowerP} we prove that there is a threshold function for the property $\mathcal{A}_s$. This is done by introducing an auxiliary property called $\mathcal{B}_s$ and providing a sharp threshold for it. We establish an upper bound for the aforementioned threshold in Section \ref{secUpperP} by introducing a weakly $K_s$-saturated subgraph of $G(n,p)$ with the desired size for a regime of $p$. Finally, we find a universal upper bound for $\mathrm{wsat}\big({G}(n, p), K_s\big)$ to also cover the gap of $p$ between the provided lower bound and upper bound on the threshold in Section \ref{secUpperwsat}.




%For an event  sequence $\mathscr{E}_n$,  we say  that  $\mathscr{E}_n$ holds {\sl with high probability} (abbreviated as {\sl whp})  if $\lim_{n\rightarrow\infty}\mathrm{ Pr}(\mathscr{E}_n)=1$. For two positive   real valued functions $f$ and $g$  defined on positive integers, 
%we write $f=\mathrm{O}(g)$ (respectively, $f=\Omega(g)$) if there exists    a  positive constant   $c$ such that $f(n)\leqslant cg(n)$ (respectively, $f(n)\geqslant cg(n)$) for any $n$ large enough. Further, 
%we write  $f=\Theta(g)$ if $f=\mathrm{O}(g)$ and  $f=\Omega(g)$. Finally, we write $f\ll g$   ($f\gg g$) if $\lim_{n\rightarrow\infty}\tfrac{f(n)}{g(n)}$ equals $0$   ($\infty$).

\section{Preliminaries}

In this section, we introduce notations and formulate several probabilistic bounds that we use in the paper.\\ % Moreover, there are a few theorems that we frequently refer to. Since those theorems have different variations, we state them here as a reference for the reader.\\

For a graph $G$, we denote  the vertex set and the edge set of   $G$  by $V(G)$ and $E(G)$, respectively.
For a vertex $v\in V(G)$, set $N_G(v)=\{x\in V(G) \, | \, v \text{   is adjacent to } x\}$ to be the neighborhood of vertex $v$ in $G$. Also for a set $U \subset V(G)$, define open and closed neighborhood of $U$ in $G$ as $N_G(U)=\cap_{u\in U} N_G(u)$, and $N_G[U]=U \cup N_G(U)$, respectively.
In addition, for  $S\subset V(G)$, we denote the induced subgraph of $G$ on $S$  by $G[S]$.\\

We also use the standard asymptotic notations. For two real-valued functions $f(n)$ and $g(n)$, we write $f(n)=O\left(g(n)\right)$ if there exists a constant $c>0$ and integer $n_0$ such that $|f(n)|\leqslant cg(n)$ for every integer $n\geqslant n_0$. Moreover, we write $f(n)=o\left(g(n)\right)$ if the same holds for any constant $c>0$. We also use the notation $f(n)=\omega\left(g(n)\right)$ if $g(n)=o\left(f(n)\right)$. Finally, we write $f(n)=\Theta\left(g(n)\right)$ if $f(n)=O\left(g(n)\right)$ and $g(n)=O\left(f(n)\right)$ simultaneously.\\




Besides the notation, let us fix the versions of probabilistic bounds that we make use of all over the paper, namely, Chernoff, Janson, and FKG inequalities. We refer the reader to \cite{RG} for proofs and seeing more details about them. 

We use the Chernoff inequality for bounding sizes of neighborhoods in random graphs in Sections \ref{secUpperP}, \ref{secUpperwsat}. 

\begin{theorem}[Chernoff bound]\cite[Theorem 2.1]{RG}
    Let $X \sim Bin(n,p)$ be a binomial random variable, $t\geq 0$. Then 
    $${\sf P}[X \leqslant np-t]\leqslant\exp \left(-\frac{t^2}{2np}\right).$$
    \label{chernoff}
\end{theorem}

In order to bound from below probabilities of non-existence of a fixed structure in random graphs, we use the following corollary of FKG inequality.\\

%Also, there are situations that there are some slightly dependent "bad" events that we do not want them to happen. There are two theorems helping us to estimate the probability of this situation. A corollary of FKG inequality helps us to provide a lower bound for it and Janson's inequality that provides an upper bound for it. We finish this section by stating both of them.
\begin{theorem}\cite[Theorem 2.12]{RG}
    Let $\mathcal{S}$ be a family of subgraphs of $K_n$. Let $X=\sum_{H\in\mathcal{S}}I(H\subset G(n,p))$ count the number of graphs from $\mathcal{S}$ that appear in $G(n,p)$. Then %, $\lambda={\sf E}X$. Then
    $${\sf P}[X=0]\geqslant \prod_{H\in \mathcal{S}}[1-{\sf P}(H\subset G(n,p))].$$%\exp\left(\frac{-\lambda}{1-\max_i {\sf E}[1_i]}\right).$$
    \label{FKG}
\end{theorem}

An upper bound is given by



\begin{theorem}[Janson's inequality]\cite[Theorem 2.18]{RG}
     With the setting of Theorem~\ref{FKG}, for $H_1,H_2\in\mathcal{S}$, let $H_1\sim H_2$ indicates that $H_1\neq H_2$ and that they share at least one edge. Define 
    $\Delta=\sum_{H_1,H_2\in\mathcal{S}:\,H_1\sim H_2}{\sf P}(H_1,H_2\subset G(n,p))$. Then
    $${\sf P}[X=0]\leqslant\exp(-{\sf E}X+\Delta/2).$$
    \label{Janson}
\end{theorem}

\section{A lower bound on $p$ and the existence of a threshold}\label{secLowerP}

In this section, we prove the existence of a threshold and present a lower bound.

\begin{theorem}
	Let $s\geq 3$ be fixed, 
	$$
	q_s(n)=n^{-\frac2{s+1}}(\ln n)^\frac{2}{(s-2)(s+1)},\quad
	c_s=\left[2\left(1-\frac{1}{s+1}\right)(s-2)!\right]^{\frac{2}{(s+1)(s-2)}}.
	$$
	Then the following hold:
	\begin{enumerate}
		\item[(i)] There exists a threshold probability for the property $\mathcal{A}_s$.
		\item[(ii)] If $p(n)\leq c_sq_s(n)$, then whp the property $\mathcal{A}_s$ does not hold in ${G}(n, p)$.
	\end{enumerate}
	\label{lower}
\end{theorem}

{\it Proof.} Below, we assume that $p>\frac{1}{n\ln n}$ since, otherwise, whp there is no $K_s$ in $G(n,p)$ and the number of edges is asymptotically smaller than $n$ (it follows from Markov's inequality, see, e.g., Chapter 3.1 of \cite{RG}).

Let $\varepsilon\in(0,1)$. Then, whp the number of edges of $G(n,p)$, hereinafter denoted by $e(G(n,p))$, belongs to $\left(\frac{n^2p}{2(1+\varepsilon)},\frac{n^2p}{2(1-\varepsilon)}\right)$ since it has binomial distribution with parameters ${n\choose 2}$ and $p$ (it follows, for example, from Chebyshev's inequality).

Let $X_s$ be the number of $s$-cliques in $G(n,p)$ and let $\varepsilon>0$. It is well known (see, e.g., Chapter 3 of \cite{RG}) that, %if $p\ll n^{-2/(s-1)}$, then whp $f({G}(n, p))=0$, which implies that $\mathrm{wsat}\big({G}(n, p), K_s\big)=e({G}(n, p))$. Also, using the same theorem, one can see that 
for $p\ll n^{-\frac{2}{s+1}}$, whp $X_s=o(n^2p)$, implying $\mathrm{wsat}\big({G}(n, p), K_s\big)=e({G}(n, p))(1+o(1))$ whp since $e({G}(n, p))-X_s\leq\mathrm{wsat}\big({G}(n, p), K_s\big)\leq e({G}(n, p))$. From this, we immediately get that whp $\mathrm{wsat}\big({G}(n, p), K_s\big)\neq\mathrm{wsat}\big(K_n, K_s\big)$ for $p\ll n^{-\frac{2}{s+1}}$ such that $p\notin I:=\left((1-\varepsilon)\frac{2s-4}{n},(1+\varepsilon)\frac{2s-4}{n}\right)$. For $p\in I$ and $s\geq 4$, whp $X_s=0$ and, therefore, the weak saturation number is exactly $e({G}(n, p))$ that is not concentrated on a single value. Finally, if $p\in\left((1-\varepsilon)\frac{2}{n},(1+\varepsilon)\frac{2}{n}\right)$, then whp the weak $K_3$-saturation number equals the difference between the number of edges and the number of triangles (whp all the triangles in $G(n,p)$ are disjoint since whp there are no subgraphs with at most 5 vertices and at least two cycles; see Theorem 3.4 of \cite{RG}). The latter random variable is also not concentrated in a unit set. This is because the number of edges has the binomial distribution with parameters ${n\choose 2}$ and $p=\Theta(1/n)$ (so, 
for any interval of size $o(\sqrt{n})$, whp it is outside this interval) while the number of triangles is bounded from above by asymptotically Poisson random variable. In other words, for a constant $L$, the property of having at most $L$ triangles is {\it decreasing}~\cite[Chapter 1.3]{RG} while the asymptotic distribution of the number of  triangles in $G(n,2(1+\varepsilon)/n)$ is Poisson; see Lemma 1.10 and Theorem 3.19 of \cite{RG}.
Summing up, for $p\ll n^{-\frac{2}{s+1}}$, whp $G(n,p)$ does not have $\mathcal{A}_s$.

Now, let $\gamma>0$ be fixed and small enough, and $p\geq n^{-\frac{2}{s+1}-\gamma}$. Also, denote the property that every edge belongs to some $K_s$ by $\mathcal{B}_s$. To finish the proof, we need the following technical lemma about $\mathcal{B}_s$.



\begin{lemma}
	Let $w_n$ be a sequence of real numbers, and let 
	$$
	p(n)=c_sq_s(n)\left[1+\frac{2\ln\ln n}{(s-2)^2(s^2+s)\ln n}+\frac{w_n}{\ln n}\right].
	$$
	Then the following hold:
	\begin{enumerate}
		\item[(i)] If $w_n\to\infty$, then whp $G(n,p)$ has $\mathcal{B}_s$.
		\item[(ii)] If $w_n\to-\infty$, then whp $G(n,p)$ does not have $\mathcal{B}_s$.
	\end{enumerate}
	\label{edge_in_clique}
\end{lemma}

{\it Proof.} See the Appendix.\\


Let $p(n)$ be as in Lemma~\ref{edge_in_clique} and $w_n\to-\infty$. As far as $G(n, p)$ contains an edge which is not contained in any copy of $K_s$, we cannot hope for $\mathcal{A}_s$ to hold. Indeed, assuming that there exists an edge $e$ in $G(n, p)$ that is not contained in any $K_s$, we immediately get that $e$ should belong to a weakly $K_s$-saturated graph. Assume that $F$ is a weakly $K_s$-saturated subgraph of $G(n,p)$ with ${s-2 \choose 2}+(n-s+2)(s-2)$ edges. Then $F\setminus e$ has ${s-2 \choose 2}+(n-s+2)(s-2)-1$ edges and is weakly $K_s$-saturated in $G(n,p)\setminus e$. But this is impossible since whp ${G}(n, p)\setminus \{e\}$ is weakly $K_s$-saturated in $K_n$ (the threshold for ${G}(n, p)$ to be weakly $K_s$-saturated in $K_n$ is at most $n^{-2/(s+1)-\gamma}$ \cite{bal}, and the same argument works for $G(n,p)\setminus \{e\}$). Part (ii) of Theorem~\ref{lower} follows.\\

To prove Part (i), consider $\mathcal{B}^*_s$, the graph property that every pair of vertices have $s-2$ adjacent common neighbors. This property is {\it increasing}~\cite[Chapter 1.3]{RG} with the {\it sharp threshold probability}~\cite[Chapter 1.6]{RG} $q^*_s(n)=(2(s-2)!)^{\frac{2}{(s+1)(s-2)}}q_s(n)$ (in the same way as in the proof of Lemma~\ref{edge_in_clique}, this fact follows from the second moment method and Theorem~\ref{Janson}, see details in~\cite{SP90}). Clearly, $\mathcal{A}_s\cap\mathcal{B}^*_s$ is increasing as well. Therefore, it has a threshold probability $r_s(n)\geq q^*_s(n)$. The following lemma concludes the proof of Theorem~\ref{lower}. $\Box$

\begin{lemma}
	$r_s(n)$ is threshold for $\mathcal{A}_s$.
\end{lemma}

{\it Proof}. Clearly, whp $G(n,p)$ has the property $\mathcal{A}_s$ if $p\gg r_s(n)$. It remains to prove the opposite for $p\ll r_s(n)$.

Let us first assume that there exist a sequence $n_k$ and a constant $C$ such that $r_s(n_k)<Cq^*_s(n_k)$ for all large enough $k$. Then, for this sequence $n_k$, the result immediately follows from Part (ii) of Theorem~\ref{lower}.

Therefore, we may assume that $r_s(n)>w_n q^*_s(n)$ for all $n$ and some $w_n\to\infty$ as $n\to\infty$. If $p(n) < c_sq_s(n)$ for infinitely many $n$, then whp (for these $n$) $G(n,p)$ does not have the property $\mathcal{A}_s$ by Part (ii) of Theorem~\ref{lower}. If $(1+\varepsilon)q^*_s(n_k)\leq p(n_k)\ll r_s(n_k)$ for some $\varepsilon>0$ and an infinite sequence $n_k$, then
$$
{\sf P}(G(n_k,p)\in\mathcal{A}_s)\leq{\sf P}(G(n_k,p)\notin\mathcal{B}^*_s)+{\sf P}(G(n_k,p)\in\mathcal{A}_s\cap\mathcal{B}^*_s)\to 0,\quad k\to\infty.
$$

Finally, assume that there exists an $\varepsilon>0$ and an infinite sequence $n_k$ (below, we omit $k$ for simplicity of notations) such that 
$$
p_*(n_k):=c_s q_s(n_k)\leq p(n_k)\leq (1+\varepsilon)q^*_s(n_k)
$$
and ${\sf P}(G(n_k,p(n_k))\in\mathcal{A}_s)\geq\delta>0$. 

Let $p_0(n)=p_*(n)\left[1+\frac{1}{\sqrt{\ln n}\ln\ln n}\right]$. If $p<p_0$, then $G(n,p_0)$ can be obtained from $G(n,p)$ by drawing every missing edge with probability $\frac{p_0-p}{1-p}$. Then, by~(\ref{expectation-mu}) and (\ref{mu}), the probability that there exists an edge $xy$ in $G(n,p_0)\setminus G(n,p)$ such that $x,y$ do not have $s-2$ adjacent common neighbors in $G(n,p)$ is at most 
$$
{n\choose 2}\frac{p_0-p}{1-p}\exp\left[-{n-2\choose s-2}p_*^{\frac{(s+1)(s-2)}{2}}+o(1)\right]=O\left(\frac{1}{\ln\ln n}\right).
$$
Therefore,
$$
{\sf P}(G(n,p_0)\in\mathcal{A}_s)\geq{\sf P}(G(n,p)\in\mathcal{A}_s)-O\left(\frac{1}{\ln\ln n}\right)\geq\delta-o(1).
$$

So we may assume that $p\geq p_0$. In the same manner, $G(n,(1+\varepsilon)q^*_s(n))$ can be obtained from $G(n,p)$ by drawing every missing edge. Then, the probability that there exists an edge $xy$ in $G(n,(1+\varepsilon)q^*_s(n))\setminus G(n,p)$ such that $x,y$ do not have $s-2$ adjacent common neighbors in $G(n,p)$ is at most 
$$
{n\choose 2}\frac{(1+\varepsilon)q^*_s(n)-p}{1-p}\exp\left[-{n-2\choose s-2}p_0^{\frac{(s+1)(s-2)}{2}}+o(1)\right]=O\left([\ln n]^{\frac{2}{(s-2)(s+1)}}\exp\left[-\frac{\sqrt{\ln n}}{\ln\ln n}\right]\right).
$$
Therefore,
$$
{\sf P}(G(n,(1+\varepsilon)q^*_s(n))\in\mathcal{A}_s)\geq{\sf P}(G(n,p)\in\mathcal{A}_s)-o(1)\geq\delta-o(1),
$$
a contradiction. $\Box$




%Notice that, for any $p=p(n)\in[0,1]$, whp $e({G}(n, p))\neq{s-2 \choose 2}+(n-s+2)(s-2)$, since

%This results in the lower bound $n^{-2/(s+1)}$ for the property $\mathcal{A}_s$. Note that for $p= ({2s-4})/n$, some non trivial concentration arguments are needed to prove that $A_s$ does not hold whp. For $s>3$, as whp there is no copy of $K_s$ in ${G}(n, ({2s-4})/n)$, we have $\mathrm{wsat}\big({G}(n, p), K_s\big)=e({G}(n, p))$ which is not exactly ${s-2 \choose 2}+(n-s+2)(s-2)$ whp. Also for $s=3$, the number of copies of $K_3$ in ${G}(n, 2/n)$ is a random variable with Poisson distribution. Subtracting from the number of edges we would not exactly obtain ${s-2 \choose 2}+(n-s+2)(s-2)$ whp.







\section{Upper bound on $p$}\label{secUpperP}

\begin{theorem}
	Let $s\geqslant 3$ be an integer. If $p\geq n^{-\frac{1}{2s-3}}(\ln n)^2$, then $G(n,p)$ has the property $\mathcal{A}_s$ whp.
	\label{th_upper}
\end{theorem}

{\it Proof.} Since for $p$ in the range, whp $G(n,p)$ is weakly $K_s$-saturated in $K_n$ (see~\cite{bal}), we get that whp $\mathrm{wsat}(G(n,p),K_s)\geq\mathrm{wsat}(K_n,K_s)$.

It remains to prove that whp there exists a weakly $K_s$-saturated subgraph of $G(n,p)$ with ${s-2\choose 2}+(n-s+2)(s-2)$ edges. Below, we define two graph properties that imply such weak saturation `stability'. To define these properties, let us recall the following definition. {\it The $k$-th power of a graph} $G$ is the graph $G^k$ on the same vertex set such that $x,y$ are adjacent in $G^k$ if and only if the distance between them in $G$ is at most $k$.

Let $\mathrm{EXT}$ be the graph property `every set of $s$ vertices has $s-2$ common neighbors inducing a complete graph' and $\mathrm{HAM}$ be the graph property `for every set of $s-1$ vertices, its common neighborhood induces a graph containing $(s-2)$-th power of a Hamiltonian path'.

The following two lemmas conclude the proof of Theorem~\ref{th_upper}. $\Box$

\begin{lemma}\label{l1}
	If $\mathrm{EXT}$ and $\mathrm{HAM}$ hold for a graph $G$ with $n$ vertices, then $\mathrm{wsat}(G,K_s)\leq\mathrm{wsat}(K_n,K_s)$.
\end{lemma}

\begin{lemma}\label{l2}
	If $p\geq n^{-\frac1{2s-3}}(\ln n)^{2}$, then ${\sf P}(G(n, p)\in\mathrm{EXT}\cap\mathrm{HAM})\to 1$ as $n\to\infty$.
\end{lemma}


{\it Proof of Lemma~\ref{l1}.} Assume that $G$ is a graph satisfying $\mathrm{EXT}$ and $\mathrm{HAM}$. Let $H_0$ be a copy of $K_{s-2}$ in $G$. Define a weakly $K_s$-saturated spanning subgraph $H \subset G$ as follows. $H$ contains all edges of $H_0$, and also all edges of $G$ between $H_0$ and $N_G(H_0)$. We still have to add some other edges going outside $N_G[H_0]$. For every $v \in V(G)\setminus N_G[H_0]$, we add $s-2$ edges adjacent to $v$ described below. By the property $\mathrm{HAM}$, the graph $F_v$ induced on $N_G\big(V(H_0) \cup \{v\}\big)$ contains a copy of $(s-2)$-th power of a Hamiltonian path. Starting from an arbitrary vertex, denote the vertices of $F_v$ going in the natural order induced by the Hamiltonian path, by $x^v_1,x^v_2,\ldots,x^v_{f_v}$, where $f_v=|V(F_v)|$. We add edges $vx^v_1,vx^v_2,\ldots,vx^v_{s-2}$ to $H$. It is easy to see that $H$ is of size ${s-2 \choose 2}+(n-s+2)(s-2)$, so it suffices to prove that $H$ is weakly $K_s$-saturated in $G$. 

First, all edges between the vertices of $N_G(H_0)$ can be `infected' since they belong to $K_s$ containing $H_0$. Second, for each $v \in V(G)\setminus N_G[H_0] $, we may `infect' edges $vx^v_{s-1},vx^v_s,\ldots,xv^v_{f_v}$ one by one since every such edge belongs to the $s$-clique containing previous $s-2$ vertices of the $(s-2)$-th power of the Hamiltonian path. Finally, each edge $xy$ between vertices of $V(G) \setminus N_G[H_0]$ can be `infected', since by the property $\mathrm{EXT}$, $N_G(\{x,y\}\cup V(H_0))$ contains a copy of $K_{s-2}$, say $K^*$. But note that $V(K^*)\subset N_G(V(H_0))$, so $xy$ is the last edge of the $s$-clique $G[V(K^*)\cup \{x,y\}]$ and hence can be `infected' as well. $\Box$\\



{\it Proof of Lemma~\ref{l2}.} It is known~\cite{SP90} that, for $p\gg n^{-\frac{2}{3(s-1)}}[\ln n]^{\frac{2}{3(s-2)(s-1)}}$, whp $G(n,p)$ has the property $\mathrm{EXT}$.

To prove the second property, notice that, for $k\in\mathbb{N}$, $r\in\mathbb{N}$, if $p(m)\gg m^{-\frac 1k}(\ln m)^4$, then $G(m, p)$ contains the $k$-th power of a Hamiltonian path with probability at least $1-m^{-r}$. This follows from the fact (see  \cite{posa}, Theorem 1.6 of \cite{fischer}, and Theorem 1.1 of \cite{kuhn}) that
there exists $C$ such that if $p^*(m) > C m^{-\frac 1k}(\ln m)^3$, then ${G}(m, p^*)$ contains the $k$-th power of a Hamiltonian path with probability at least $1-1/e$. To boost this probability to $1-m^{-r}$ it suffices to take the union of $r\ln m $ independent copies of ${G}(m, p^*)$ on $[m]$ and set $p=1-(1-p^*)^{r\ln m}$.


Fix $W_0\subset[n]$ of size $s-1$ and set $m=\frac{np^{s-1}}{2}$. Then, by Theorem~\ref{chernoff}, %Let $a_m=\mathrm{Pr}(\text{Bin}(n-s+1,p^{s-1})=m)$ and $b_m$ be the probability that ${G}(m, p)$ does not contain the $(s-2)$-th power of a Hamiltonian cycle. Then, 
the probability that the common neighborhood of $W_0$ does not contain the $(s-2)$-th power of a Hamiltonian path is at most
$$
{\sf P}(|N_{G(n,p)}(W_0)|<m)+m^{-3s}{\sf P}(|N_{G(n,p)}(W_0)|\geq m)\leq e^{-\frac{m}{4}}+n^{-s}.
$$
From the union bound, the result follows. $\Box$

\begin{remark}
	The power in the log factor in Theorem~\ref{th_upper} is not the best possible. Using best known estimations of threshold probability for containing the $k$-th power of a Hamiltonian path, we may replace $[\ln n]^2$ with $[\ln n]^{1/3+\varepsilon}$ for $s=3$, $[\ln n]^{8/5}$ for $s=4$ and $[\ln n]^{1/2}$ for $s\geqslant 5$.
	\label{rmrk}
\end{remark}

\section{Upper bound on $\mathrm{wsat}\big({G}(n, p), K_s\big)$}\label{secUpperwsat}

From the previous arguments, we know that whp $\mathrm{wsat}\big({G}(n, p), K_s\big)=e(G(n,p))(1+o(1))$ when $p\ll n^{-\frac{2}{s+1}}$ and $\mathrm{wsat}\big({G}(n, p), K_s\big)={s-2\choose 2}+(n-s+2)(s-2)$  when $p\geq n^{-\frac{1}{2s-3}}(\ln n)^{\beta}$, where $\beta=1/3+\varepsilon$ for $s=3$, $\beta=8/5$ for $s=4$ and $\beta=1/2$ for $s\geqslant 5$. In this section, we prove an upper bound for $\mathrm{wsat}\big({G}(n, p), K_s\big)$ for all the remaining values of $p$ (the trivial lower bound equals ${s-2\choose 2}+(n-s+2)(s-2)$ whp since $G(n,p)$ is weakly saturated in $K_n$ for those values of $p$ whp \cite{bal}).


\begin{thm}\label{upperbd}
	Let $\gamma=1$ for $s=3$, $\gamma=6$ for $s=4$ and $\gamma=0$ for $s\geq 5$. Let $w_n\to\infty$ as $n\to\infty$. Then  whp $$\mathrm{wsat}\big(G(n, p), K_s\big)\leqslant n(s-2)+ \frac{w_n(\ln n)^{2(\gamma+s-2)}}{p^{2s-3}}.$$
\end{thm}
\begin{proof}

For $p\leq\left((\ln n)^{\gamma+s-2}/n\right)^{1/(s-1)}$, the result is immediate since whp $|E(G(n,p))|\ll\frac{w_n(\ln n)^{2(\gamma+s-2)}}{p^{2s-3}}$. For $p\geq n^{-\frac{1}{2s-3}}(\ln n)^{\beta}$ the result follows from Remark~\ref{rmrk}. Let 
$$
\left((\ln n)^{\gamma+s-2}/n\right)^{1/(s-1)}<p<n^{-\frac{1}{2s-3}}(\ln n)^{\beta}.
$$

Let $G$ be a graph and let  $X$ be a subset of  $V(G)$ having  two properties: 
	\begin{itemize}
		\item [(i)] For  every vertex $v\in \overline{X}=V(G)\setminus X$ the subgraph of $G$ induced on $N_G(v)\cap X$  contains an $(s-2)$-th power of a Hamiltonian path.
		\item [(ii)] Any two distinct vertices $v,w\in \overline{X}$ have $s-2$ pairwise adjacent common neighbors in $X$.
	\end{itemize}
 Let	$H$ be a spanning subgraph of $G$ containing all edges with both endpoints in $X$ and $(s-2)|\overline{X}|$ more edges such that every vertex $v\in\overline{X}$ belongs to exactly $s-2$ edges $\{v,w_1\},\ldots,\{v,w_{s-2}\}$ where $w_1,\ldots,w_{s-2}$ are initial vertices of an $(s-2)$-th power of a Hamiltonian path of $G[N_G(v)\cap X]$.

Let us show that $H$ is weakly $K_s$-saturated in $G$. Note that all edges with both endpoints in $X$ are already `infected' by definition. Furthermore, all edges having one vertex in $X$ can be `infected' in the same way, as in the proof of Lemma~\ref{l1}. Finally, let $\tilde H$ have all edges of $H$ and all edges between $X$ and $\overline{X}$ that are all present in $G$. Let $v,w\in\overline{X}$ be adjacent in $G$. Then, the property (ii) ensures that adding the edge $\{v,w\}$ to $\tilde H$ creates a copy of $K_s$. Thus, $\mathrm{wsat}(G, K_s)\leqslant (s-2)|\overline{X}|+e(G[X])$.
	
Let $G=G(n, p)$. Let $m=\left\lfloor\frac{(\ln n)^{\gamma+s-2}}{p^{s-1}}\sqrt{w_n}\right\rfloor$, $X=[m]$. Since whp $e(G[X])\leq m^2p $, it remains to show that whp (i) and (ii) hold for $G$ with our choice of $X$. 

As we noticed in the proof of Lemma~\ref{l2}, for any  $\ell$, the relation $p\gg \ell^{-\frac {1}{s-2}}(\ln n)^{\gamma/(s-2)+1}$ implies that $G(n,p)[\ell]$ contains the $(s-2)$-th power of a Hamiltonian path with probability at least $1-o(1/n)$ (actually, the power of log-factor in the proof of Lemma~\ref{l2} is 4, but it can be improved in this way due to best known estimations of threshold probability for containing the $k$-th power of a Hamiltonian path, see~\cite{Frieze_Survey}). Given a vertex $v\in[n]\setminus[m]$, with probability $o(1/n)$, it has less than $\frac{(\ln n)^{\gamma+s-2}}{p^{s-2}}\sqrt[4]w_n$ neighbors in $[m]$ by Theorem~\ref{chernoff}. Property (i) follows.

Finally, by Theorem~\ref{Janson}, the probability that, there exist distinct  $v,w\in \overline{X}$ without $s-2$ pairwise adjacent common neighbors in $[\tilde m]$, $\tilde m=\left\lfloor\frac{\ln n}{p^{(s+1)/2}}\right\rfloor<m$, is at most
\begin{align*}
 {n\choose 2}&\exp\left(-{\tilde m\choose s-2}p^{{s\choose 2}-1}+\sum_{t=1}^{s-3}{\tilde m\choose s-2}{s-2\choose t}{\tilde m-s+2\choose s-2-t}p^{(s+1)(s-2)-2t-{t\choose 2}}\right)\leq\\
 &\exp\left(2\ln n-\frac{1}{(s-2)!}\tilde m^{s-2}p^{(s+1)(s-2)/2}(1-o(1))\right)\to 0,\quad n\to\infty. \qedhere
\end{align*} 
\end{proof}


%\begin{thm}\label{upperbd}
%	If  $p\geqslant 3\sqrt{\ln n/n}$,  then whp $$\text{ wsat}\big(\mathbbmsl{G}(n, p), K_3\big)\leqslant n+ \frac{41(\ln n)^2}{p^3}.$$
%\end{thm}

\section*{Acknowledgments}

Maksim Zhukovskii gratefully acknowledge the financial support from the Ministry of Educational and Science of the Russian Federation in the framework of MegaGrant no 075-15-2019-1926


\begin{thebibliography}{99}

\bibitem{Adler}
{\sc J. Adler} and {\sc U. Lev}, Bootstrap percolation: visualizations and applications, {\sl Braz. J. Phys.} {33} (2003), 641{--}644.

\bibitem{Alon85}
{\sc  N. Alon}, An extremal problem for sets with applications to graph theory.
{\sl J. Combin. Theory Ser. A}, {40} (1985), 82-–89.


\bibitem{bal}
{\sc  J. Balogh}, {\sc B. Bollob\'as }  and  {\sc R. Morris}, Graph bootstrap percolation,
{\sl Random Structures Algorithms }41 (2012), 413{--}440.



\bibitem{bol}
{\sc  B. Bollob\'as},   Weakly  $k$-saturated graphs, 1968 {\sl Beitr\"age zur {G}raphentheorie   (Kolloquium, Manebach,
	1967)}, pp.  25{--}31, Teubner, Leipzig.


\bibitem{thresh}
{\sc  B. Bollob\'as} and {\sc A.  Thomason},   Threshold functions,  {\sl Combinatorica} { 7} (1987),  35{--}38.

\bibitem{Faudree11}
{\sc  J.R. Faudree}, {\sc  R.J. Faudree} and {\sc J.R.  Schmitt},   A survey of minimum saturated graphs,  {\sl Electron. J. Comb.} (2011),  DS19-Jul.

\bibitem{fischer}
{\sc M. Fischer} , {\sc N. \v Skori\'c}, {\sc A. Steger} and {\sc M. Truji\'c}, Triangle resilience of the square of a Hamilton cycle in random graphs, {\sl arXiv:1809.07534} (2018).

\bibitem{Fontes}
{\sc L.R. Fontes}, {\sc R.H. Schonmann} and {\sc V. Sidoravicius}, Stretched exponential fixation in stochastic Ising
models at zero temperature, {\sl Comm. Math. Phys.} {228} (2002), 495{--}518.

\bibitem{Frankl82}
{\sc P. Frankl}, An extremal problem for two families of sets. {\sl European J.
Combin.}, {3} (1982), 125-–127.

\bibitem{Frieze_Survey} 
{\sc A. Frieze}, Hamilton cycles in random graphs: a bibliography, {\sl arXiv:1901.07139} (2019).

\bibitem{Janson}
{\sc  S. Janson}, {\sc T. \L uczak} and {\sc A. Ruci\'{n}ski}, An exponential bound for the probability of nonexistence of a specified subgraph in a random graph, {\sl Random graphs '87}, (Pozna\'{n}, 1987), 73{--}87 Wiley, Chichester, 1990.

\bibitem{RG}
{\sc  S. Janson}, {\sc T. \L uczak} and {\sc A. Ruci\'{n}ski},  {\sl Random Graphs, John Wiley \& Sons, Inc.}, 2000.

\bibitem{Kalai84}
{\sc  G. Kalai}, Weakly saturated graphs are rigid. {\sl Convexity and graph theory}, {87} (1984), 189-–190.

\bibitem{Kalai85}
{\sc  G. Kalai}, Hyperconnectivity of graphs. {\sl Graphs Combin.}, {1} (1985), 650–-79.

\bibitem{kor}
{\sc D. Kor\'andi} and {\sc B. Sudakov}, Saturation in random graphs, {\sl Random Structures  Algorithms}  {  51} (2017),  169--181.

\bibitem{kuhn}
{\sc D. K\"{u}hn}  and {\sc D. Osthus}, On P\'osa’s conjecture for random graphs, {\sl SIAM J. Discrete Math.} {26} (2012), 1440{--}1457.

\bibitem{L77}
{\sc L.  Lov\'{a}sz}, Flats in matroids and geometric graphs, {\sl  Combinatorial surveys (Proc. Sixth British Combinatorial Conf., Royal Holloway Coll., Egham, 1977)}, pp. 45{--}86, Academic Press, London, 1977.

\bibitem{Morris}
{\sc R. Morris}, Zero-temperature Glauber dynamics on $\mathbb{Z}^d$, {\sl Probab. Theory Related Fields} {149} (2011), 417{--}434.

\bibitem{Neumann}
{\sc J. von Neumann}, {\sl Theory of Self-Reproducing Automata}, Univ. Illinois Press, Urbana, 1966.

\bibitem{posa}
{\sc L.  P\'osa}, Hamiltonian circuits in random graphs, {\sl Discrete Math.} { 14} (1976), 359{--}364.

\bibitem{SP90}
{\sc J.H. Spencer}, Threshold functions for extension statements, {\sl  J. Combin. Theory Ser. A} { 53} (1990), 286{--}305.

\bibitem{Ulam}
{\sc S. Ulam}, Random processes and transformations, {\sl  Proceedings of the International Congress of Mathematicians}, Vol. 2, Cambridge, Mass., 1950, pp. 264{--}275, Amer. Math. Soc., Providence, R. I., 1952.

\bibitem{Yu93}
{\sc  J. T. Yu}, An extremal problem for sets: a new approach via Bezoutians. {\sl J. Combin. Theory Ser. A}, {62} (1993), 170–-175.

\end{thebibliography}




\section*{Appendix}


{\it Proof of Lemma \ref{edge_in_clique}.} In~\cite{SP90}, it is proven that there exists $R$ such that, for $p>Rq_s(n)$, whp every pair of vertices have $s-2$ adjacent common neighbors. Therefore, we may assume that $w_n\leq R\ln n$.\\

Below, we, as usual, apply the second moment method and Theorem~\ref{Janson}. Let $N_s$ be the number of edges that do not belong to any $K_s$.

Let $u,v\in[n]$ be distinct, and $W:=\{w_1,\ldots,w_{s-2}\}\subset[n]\setminus\{u,v\}$. Consider an event $K[W]$ saying that each  $w_i$ is adjacent to both $u,v$ and every other $w_j$ in $G(n,p)$. Let $\mu(u,v)$ counts the number of sets $W$ as above such that $K[W]$ occurs. Then, 
\begin{equation}
{\sf E}N_s={n\choose 2}p{\sf P}(\mu(1,2)=0).
\label{expectation-mu}
\end{equation}
If $s=3$, then ${\sf P}(\mu(1,2)=0)=(1-p^2)^{n-2}$. For $s\geq 4$, compute
$$
\sum_W {\sf P}(K[W])={n-2\choose s-2}p^{\frac{(s+1)(s-2)}{2}}=:\lambda,
$$
$$
\sum_{W_1,W_2}{\sf P}(K[W_1]\cap K[W_2])=\sum_{\ell=1}^{s-3}{n-2\choose s-2}{s-2\choose\ell}{n-s\choose s-2-\ell}p^{(s+1)(s-2)-\frac{(\ell+3)\ell}{2}}=\Delta,
$$
where the first summation is over $W\in{[n]\setminus\{u,v\}\choose s-2}$, and the second one is over distinct $W_1,W_2\in{[n]\setminus\{u,v\}\choose s-2}$ having a non-empty intersection. Then, Theorem~\ref{FKG} and Theorem~\ref{Janson} imply that
$$
\mathrm{exp}\left[-\lambda\left(1+O\left(p^{\frac{(s+1)(s-2)}{2}}\right)\right)\right]\leq{\sf P}(\mu(1,2)=0)\leq
\mathrm{exp}\left[-\lambda+\Delta/2\right].
$$
For the considered values of $p$, $\Delta=o(\lambda\cdot n^{-1/(s+1)}\ln n)$. Therefore, since $\lambda=O(\ln n)$ we have

\begin{align}
{\sf P}(\mu(1,2)=0)=\exp\left[-\lambda\left(1+o\left(n^{-1/(s+1)}\ln n\right)\right)\right] &=e^{-\lambda}\exp\left[ o\left(n^{-1/(s+1)}\ln^2 n\right)\right]\nonumber\\ &=e^{-\lambda}\left(1+o\left(n^{-1/(s+1)}\ln^2 n\right)\right).
\label{mu}
\end{align}




If $w_n\to\infty$, then 
\begin{align*}
\lambda = \frac{n^{s-2}}{(s-2)!}\left[2\left(1-\frac{1}{s+1}\right)(s-2)!\right]n^{-(s-2)}\ln n\left[1+\frac{\ln\ln n}{s(s-2)\ln n}+\omega\left(\frac{1}{\ln n}\right)\right]&
\\
=2\left(1-\frac{1}{s+1}\right)\ln n+\frac{2\ln\ln n}{(s+1)(s-2)}+\omega(1).&
\end{align*}

Therefore,

\begin{align*}
{\sf E}N_s&\leq{n\choose 2}p e^{-\lambda+\Delta/2}\leq\mathrm{exp}[2\ln n+\ln p-\lambda+O(1)]\\
&=\exp\left[2\ln n-\frac{2\ln n }{s+1}+\frac{2\ln\ln n}{(s-2)(s+1)} - 2\left(1-\frac{1}{s+1}\right)\ln n-\frac{2\ln\ln n}{(s+1)(s-2)}-\omega(1)\right],
\end{align*}
which goes to zero and thus part (i) follows.\\

If $w_n\to-\infty$, then 
$$
{\sf E}N_s\geq{n\choose 2}p \exp\left[-\lambda\left(1+O(n^{-(s-2)}\ln n)\right)\right]\geq\exp[2\ln n+\ln p-\lambda+o(1)]\to\infty.
$$ 
To finish the proof of Part (ii), we need the second moment. Similarly, using Theorem~\ref{Janson}, we estimate ${\sf P}(\mu(1,2)=0,\mu(3,4)=0)$ and ${\sf P}(\mu(1,2)=0,\mu(2,3)=0)$.

For $W:=\{w_1,\ldots,w_{s-2}\}\subset[n]\setminus[4]$, consider an event $K'[W]$ saying that each  $w_i$ is either adjacent to both $1,2$, or adjacent to both $3,4$ and every other $w_j$ in $G(n,p)$. Let $\mu'$ counts the number of sets $W$ as above such that $K'[W]$ happens. Then, 
\begin{equation}
{\sf P}(\mu(1,2)=0,\mu(3,4)=0)\leq{\sf P}(\mu'=0).
\label{mu-one}
\end{equation}
If $s=3$, then ${\sf P}(\mu'=0)=(1-p^2)^{2(n-4)}$. For $s\geq 4$, compute
$$
\sum_W {\sf P}(K'[W])={n-4\choose s-2}p^{\frac{(s+1)(s-2)}{2}}(2-p^{2(s-2)})=:\lambda'=2\lambda(1+O(1/n)),
$$
$$
\sum_{W_1,W_2}{\sf P}(K'[W_1]\cap K'[W_2])= 
\sum_{\ell=1}^{s-3}{n-4\choose s-2}{s-2\choose\ell}{n-s-2\choose s-2-\ell}\times
$$
$$ 
p^{(s-2)(s-3)-\frac{(\ell-1)\ell}{2}}2p^{2\ell}\left(2p^{2(s-2)-2\ell}\right)^2(1+O(p))=:\Delta'=8\Delta(1+O(q_s(n))),
$$
where the first summation is over $W'\in{[n]\setminus[4]\choose s-2}$, and the second one is over distinct $W_1,W_2\in{[n]\setminus[4]\choose s-2}$ having a nonempty intersection. Then, Theorem~\ref{Janson} implies that
$$
{\sf P}(\mu'=0)\leq
\mathrm{exp}\left[-\lambda'+\Delta'/2\right]=\mathrm{exp}\left[-2\lambda(1+O(1/n))+4\Delta(1+O(q_s(n)))\right]=
$$
\begin{equation}
\exp\left[-2\lambda\left(1+o\left(n^{-1/(s+1)}\ln n\right)\right)\right]=e^{-2\lambda}\left(1+o\left(n^{-1/(s+1)}\ln^2 n\right)\right).
\label{mu-one-from-above}
\end{equation}

In the same way, let us estimate ${\sf P}(\mu(1,2)=0,\mu(2,3)=0)$. For $W:=\{w_1,\ldots,w_{s-2}\}\subset[n]\setminus[3]$, consider an event $K''[W]$ saying that each  $w_i$ is either adjacent to both $1,2$, or adjacent to both $2,3$ and every other $w_j$ in $G(n,p)$. Let $\mu''$ counts the number of sets $W$ as above such that $K''[W]$ happens. Then, 
\begin{equation}
{\sf P}(\mu(1,2)=0,\mu(2,3)=0)\leq{\sf P}(\mu''=0).
\label{mu-two}
\end{equation}
If $s=3$, then ${\sf P}(\mu''=0)=(1-p+p(1-p)^2)^{n-3}$. For $s\geq 4$, compute
$$
\sum_W {\sf P}(K''[W])={n-3\choose s-2}p^{\frac{(s+1)(s-2)}{2}}(2-p^{s-2})=:\lambda''=2\lambda(1+o(1/\sqrt{n})),
$$
$$
\sum_{W_1,W_2}{\sf P}(K''[W_1]\cap K''[W_2])= 
\sum_{\ell=1}^{s-3}{n-3\choose s-2}{s-2\choose\ell}{n-s-1\choose s-2-\ell}\times
$$
$$ 
p^{(s-2)(s-3)-\frac{(\ell-1)\ell}{2}}p^{2(s-2)-\ell}8p^{\ell}p^{2((s-2)-\ell)}(1+O(p))=:\Delta''=8\Delta(1+O(q_s(n))),
$$
where the first summation is over $W'\in{[n]\setminus[3]\choose s-2}$, and the second one is over distinct $W_1,W_2\in{[n]\setminus[3]\choose s-2}$ having a non-empty intersection. Then, Theorem~\ref{Janson} implies that
$$ 
{\sf P}(\mu''=0)\leq
\mathrm{exp}\left[-\lambda''+\Delta''/2\right]=\mathrm{exp}\left[-2\lambda(1+O(1/\sqrt{n}))+4\Delta(1+O(q_s(n)))\right]=
$$
\begin{equation}
\exp\left[-2\lambda\left(1+o\left(n^{-1/(s+1)}\ln n\right)\right)\right].
\label{mu-two-from-above}
\end{equation}
Then, relations (\ref{expectation-mu})--(\ref{mu-two-from-above}) imply
$$
\mathrm{Var}N_s={\sf E}N_s^2-({\sf E}N_s)^2={\sf E}N_s+{n\choose 2}{n-2\choose 2}p^2{\sf P}(\mu(1,2)=\mu(3,4)=0)+
$$
$$
n(n-1)(n-2)p^2{\sf P}(\mu(1,2)=\mu(2,3)=0)-\left({n\choose 2}p{\sf P}(\mu(1,2)=0)\right)^2\leq 
$$
$$
{\sf E}N_s+{n\choose 2}^2 p^2 e^{-2\lambda}\left(1+o\left(n^{-1/(s+1)}\ln^2 n\right)\right)+
$$
$$
n^3p^2 e^{-2\lambda}\left(1+o\left(n^{-1/(s+1)}\ln^2 n\right)\right) - {n\choose 2}^2 p^2 e^{-2\lambda}\left(1+o\left(n^{-1/(s+1)}\ln^2 n\right)\right)=o({\sf E}^2N_s).
$$
Part (ii) follows from Chebyshev's inequality. $\Box$\\




\end{document}
